{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-26T20:18:18.762636Z",
     "start_time": "2024-09-26T20:18:17.517618Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "from dataset.texts import valid_symbols\n",
    "from lightspeech import FeedForwardTransformer\n",
    "from utils.hparams import load_hparam_str\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:17:18.706236Z",
     "start_time": "2024-09-26T20:17:18.523358Z"
    }
   },
   "cell_type": "code",
   "source": "ckpt = torch.load(\"/home/hadware/Code/ogmios-workbench/LightSpeech/checkpoints/ljspeech/ljspeech_fastspeech_d9290f7_1k_steps.pyt\")",
   "id": "c4a4cd0877608c77",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_308221/4293489179.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(\"/home/hadware/Code/ogmios-workbench/LightSpeech/checkpoints/ljspeech/ljspeech_fastspeech_d9290f7_1k_steps.pyt\")\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:20:07.822345Z",
     "start_time": "2024-09-26T20:20:07.734402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hp = load_hparam_str(ckpt['hp_str'])\n",
    "idim = len(valid_symbols)\n",
    "odim = hp.audio.num_mels\n",
    "model = FeedForwardTransformer(idim, odim, hp)"
   ],
   "id": "85e66a35c27407e4",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:21:11.598003Z",
     "start_time": "2024-09-26T20:21:11.586990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def module_size_in_mb(module):\n",
    "    param_size = sum(param.nelement() * param.element_size() for param in module.parameters())\n",
    "    buffer_size = sum(buffer.nelement() * buffer.element_size() for buffer in module.buffers())\n",
    "    size_mb = (param_size + buffer_size) / 1024 ** 2\n",
    "    return size_mb\n",
    "\n",
    "\n",
    "def print_module_sizes(model, indent=0):\n",
    "    size_mb = module_size_in_mb(model)\n",
    "    print(f'{\" \" * indent}Module: {model.__class__.__name__}, Size: {size_mb:.2f} MB')\n",
    "\n",
    "    for name, child in model.named_children():\n",
    "        print_module_sizes(child, indent + 2)\n",
    "\n",
    "\n",
    "print_module_sizes(model)"
   ],
   "id": "ffe9682d229f98e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module: FeedForwardTransformer, Size: 40.27 MB\n",
      "  Module: Encoder, Size: 19.11 MB\n",
      "    Module: LayerNorm, Size: 0.00 MB\n",
      "    Module: Sequential, Size: 4.97 MB\n",
      "      Module: Embedding, Size: 0.08 MB\n",
      "      Module: ScaledPositionalEncoding, Size: 4.88 MB\n",
      "        Module: Dropout, Size: 0.00 MB\n",
      "    Module: ModuleList, Size: 14.14 MB\n",
      "      Module: EncoderLayer, Size: 3.53 MB\n",
      "        Module: MultiHeadedAttention, Size: 1.00 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: MultiLayeredSepConv1d, Size: 2.02 MB\n",
      "          Module: SepConv1d, Size: 1.01 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: SepConv1d, Size: 1.01 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: Dropout, Size: 0.00 MB\n",
      "        Module: Linear, Size: 0.50 MB\n",
      "      Module: EncoderLayer, Size: 3.55 MB\n",
      "        Module: MultiHeadedAttention, Size: 1.00 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: MultiLayeredSepConv1d, Size: 2.04 MB\n",
      "          Module: SepConv1d, Size: 1.03 MB\n",
      "            Module: Conv1d, Size: 0.03 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: SepConv1d, Size: 1.01 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: Dropout, Size: 0.00 MB\n",
      "        Module: Linear, Size: 0.50 MB\n",
      "      Module: EncoderLayer, Size: 3.54 MB\n",
      "        Module: MultiHeadedAttention, Size: 1.00 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: MultiLayeredSepConv1d, Size: 2.03 MB\n",
      "          Module: SepConv1d, Size: 1.02 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: SepConv1d, Size: 1.01 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: Dropout, Size: 0.00 MB\n",
      "        Module: Linear, Size: 0.50 MB\n",
      "      Module: EncoderLayer, Size: 3.53 MB\n",
      "        Module: MultiHeadedAttention, Size: 1.00 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: MultiLayeredSepConv1d, Size: 2.02 MB\n",
      "          Module: SepConv1d, Size: 1.01 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: SepConv1d, Size: 1.01 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: Dropout, Size: 0.00 MB\n",
      "        Module: Linear, Size: 0.50 MB\n",
      "  Module: DurationPredictor, Size: 0.51 MB\n",
      "    Module: ModuleList, Size: 0.51 MB\n",
      "      Module: Sequential, Size: 0.26 MB\n",
      "        Module: SepConv1d, Size: 0.25 MB\n",
      "          Module: Conv1d, Size: 0.00 MB\n",
      "          Module: Conv1d, Size: 0.25 MB\n",
      "        Module: ReLU, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "          Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: Dropout, Size: 0.00 MB\n",
      "      Module: Sequential, Size: 0.26 MB\n",
      "        Module: SepConv1d, Size: 0.25 MB\n",
      "          Module: Conv1d, Size: 0.00 MB\n",
      "          Module: Conv1d, Size: 0.25 MB\n",
      "        Module: ReLU, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "          Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: Dropout, Size: 0.00 MB\n",
      "    Module: Linear, Size: 0.00 MB\n",
      "  Module: EnergyPredictor, Size: 0.52 MB\n",
      "    Module: VariancePredictor, Size: 0.51 MB\n",
      "      Module: ModuleList, Size: 0.51 MB\n",
      "        Module: Sequential, Size: 0.26 MB\n",
      "          Module: SepConv1d, Size: 0.25 MB\n",
      "            Module: Conv1d, Size: 0.00 MB\n",
      "            Module: Conv1d, Size: 0.25 MB\n",
      "          Module: ReLU, Size: 0.00 MB\n",
      "          Module: LayerNorm, Size: 0.00 MB\n",
      "            Module: LayerNorm, Size: 0.00 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: Sequential, Size: 0.26 MB\n",
      "          Module: SepConv1d, Size: 0.25 MB\n",
      "            Module: Conv1d, Size: 0.00 MB\n",
      "            Module: Conv1d, Size: 0.25 MB\n",
      "          Module: ReLU, Size: 0.00 MB\n",
      "          Module: LayerNorm, Size: 0.00 MB\n",
      "            Module: LayerNorm, Size: 0.00 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "      Module: Linear, Size: 0.00 MB\n",
      "  Module: Linear, Size: 0.25 MB\n",
      "  Module: PitchPredictor, Size: 0.52 MB\n",
      "    Module: VariancePredictor, Size: 0.51 MB\n",
      "      Module: ModuleList, Size: 0.51 MB\n",
      "        Module: Sequential, Size: 0.26 MB\n",
      "          Module: SepConv1d, Size: 0.25 MB\n",
      "            Module: Conv1d, Size: 0.00 MB\n",
      "            Module: Conv1d, Size: 0.25 MB\n",
      "          Module: ReLU, Size: 0.00 MB\n",
      "          Module: LayerNorm, Size: 0.00 MB\n",
      "            Module: LayerNorm, Size: 0.00 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: Sequential, Size: 0.26 MB\n",
      "          Module: SepConv1d, Size: 0.25 MB\n",
      "            Module: Conv1d, Size: 0.00 MB\n",
      "            Module: Conv1d, Size: 0.25 MB\n",
      "          Module: ReLU, Size: 0.00 MB\n",
      "          Module: LayerNorm, Size: 0.00 MB\n",
      "            Module: LayerNorm, Size: 0.00 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "      Module: Linear, Size: 0.00 MB\n",
      "  Module: Linear, Size: 0.25 MB\n",
      "  Module: LengthRegulator, Size: 0.00 MB\n",
      "  Module: Encoder, Size: 19.03 MB\n",
      "    Module: LayerNorm, Size: 0.00 MB\n",
      "    Module: Sequential, Size: 4.88 MB\n",
      "      Module: ScaledPositionalEncoding, Size: 4.88 MB\n",
      "        Module: Dropout, Size: 0.00 MB\n",
      "    Module: ModuleList, Size: 14.15 MB\n",
      "      Module: EncoderLayer, Size: 3.54 MB\n",
      "        Module: MultiHeadedAttention, Size: 1.00 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: MultiLayeredSepConv1d, Size: 2.03 MB\n",
      "          Module: SepConv1d, Size: 1.02 MB\n",
      "            Module: Conv1d, Size: 0.02 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: SepConv1d, Size: 1.01 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: Dropout, Size: 0.00 MB\n",
      "        Module: Linear, Size: 0.50 MB\n",
      "      Module: EncoderLayer, Size: 3.54 MB\n",
      "        Module: MultiHeadedAttention, Size: 1.00 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: MultiLayeredSepConv1d, Size: 2.03 MB\n",
      "          Module: SepConv1d, Size: 1.03 MB\n",
      "            Module: Conv1d, Size: 0.02 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: SepConv1d, Size: 1.01 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: Dropout, Size: 0.00 MB\n",
      "        Module: Linear, Size: 0.50 MB\n",
      "      Module: EncoderLayer, Size: 3.53 MB\n",
      "        Module: MultiHeadedAttention, Size: 1.00 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: MultiLayeredSepConv1d, Size: 2.02 MB\n",
      "          Module: SepConv1d, Size: 1.01 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: SepConv1d, Size: 1.01 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: Dropout, Size: 0.00 MB\n",
      "        Module: Linear, Size: 0.50 MB\n",
      "      Module: EncoderLayer, Size: 3.54 MB\n",
      "        Module: MultiHeadedAttention, Size: 1.00 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Linear, Size: 0.25 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: MultiLayeredSepConv1d, Size: 2.03 MB\n",
      "          Module: SepConv1d, Size: 1.02 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: SepConv1d, Size: 1.01 MB\n",
      "            Module: Conv1d, Size: 0.01 MB\n",
      "            Module: Conv1d, Size: 1.00 MB\n",
      "          Module: Dropout, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: LayerNorm, Size: 0.00 MB\n",
      "        Module: Dropout, Size: 0.00 MB\n",
      "        Module: Linear, Size: 0.50 MB\n",
      "  Module: Linear, Size: 0.08 MB\n",
      "  Module: DurationPredictorLoss, Size: 0.00 MB\n",
      "    Module: MSELoss, Size: 0.00 MB\n",
      "  Module: EnergyPredictorLoss, Size: 0.00 MB\n",
      "    Module: MSELoss, Size: 0.00 MB\n",
      "  Module: PitchPredictorLoss, Size: 0.00 MB\n",
      "    Module: MSELoss, Size: 0.00 MB\n",
      "  Module: L1Loss, Size: 0.00 MB\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
